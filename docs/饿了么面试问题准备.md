#   饿了么面试问题准备

### 1. redis为什么这么快？

* 完全基于内存操作，数据存储在内存里，查找和操作都很快；
* 采用了单线程，避免了上下文切换和加锁解锁操作，性能消耗小；
* 数据结构简单，redis的数据结构是专门设计的；
* 使用多路I/O复用模型，非阻塞I/O；



### 2. redis数据类型？

5种数据类型

| 数据类型 | 可存储值               | 操作                     | 应用场景         |
| -------- | ---------------------- | ------------------------ | ---------------- |
| String   | 字符串、整数           | get set                  | 简单的键值对缓存 |
| List     | 列表                   | 两端压入或者弹出元素     | 存储列表型数据   |
| Hash     | 包含键值对的无序hash表 | 添加、移除、判断         | 存一个对象       |
| Set      | 无序集合               | 添加、移除单个元素，判断 | 交集、并集等     |
| ZSet     | 有序集合               | 根据分值排序             | 排行榜           |





### 3. redis过期策略和内存淘汰机制

**1. 为什么不能定时删除，到过期时间立即删除？**

定时删除，需要设置定时器监视key，到期就删除，这样虽然可以做到及时释放，但是占用了CPU资源，高并发请求下，CPU应该将时间用于处理请求，而不是删除key；



**2.redis为什么用定期删除+惰性删除策略**

* 惰性过期：当访问一个key时，才会判断key是否已过期，过期则清除。该策略对CPU友好，但是内存不友好。会出现大量过期key因为没被访问占用内存的情况；
* 定期过期：redis每隔100ms随机抽取expires字典中一定数量的key，检测是否过期，有过期key则删除。问题：因为随机抽取的，会存在key没有被删除的场景；

**3. 两种方法结合后还会有问题吗？**

如果定期删没有删除，然后key也没被访问到，就会使得过期key占用的内存越来越大，因此需要内存淘汰策略



**4.内存淘汰策略说说？**

8种内存淘汰策略：

* 不处理的：默认不处理新请求
* 全局键空间选择性删除：allkeys-lru、allkeys-lfu、allkeys-random；
* 设置了过期时间的key选择性删除：volatile-lru、lfu、random、  volatile-ttl（按过期时间排序，越早过期的数据优先删除）



### **4.分布式锁的实现**

```lua
// 加锁
String uuid = UUID.randomUUID().toString().replaceAll("-","");
SET key uuid NX EX 30
// 解锁
if (redis.call('get', KEYS[1]) == ARGV[1])
    then return redis.call('del', KEYS[1])
else return 0
end
```

加锁封装了2步，成为原子操作；

解锁封装了验证和del，也是原子操作；



### 5.缓存一致性问题

解决方案：cache-aside模式

问题：仍然可能有不一致的问题；

解决：

* 延迟双删方式（增加了写请求的耗时）
* 异步更新缓存（binlog+消息队列+增量消息同步到redis）



### 6.MySQL为什么用B+树做索引？

**（1）B+树和B树的对比**

* B+树非叶子节点不存储数据，只存储键值，即只存索引。而B树是存储索引和数据。Innodb的页默认是16KB，如果不存数据，那节点上可以存储更多键值（索引），这样树就会变得更矮更胖，如此一来查询数据需要进行查找的次数减少，磁盘I/O变少，查询效率变高；
* B+树所有数据在叶子节点上，数据按顺序排列的，叶子节点之间构成有序链表。且使得范围查询、排序查找变得容易。而B树因为数据分散到各个节点，实现起来不容易；

**（2）B+树和红黑树对比**

红黑树，是一种特化的平衡二叉树，数据量大时，树的层次会很高，磁盘I/O次数也会变大，不利于查找。红黑树也不支持范围查询、顺序查找；

**（3）B+树和Hash索引对比**

Hash索引适用于等值查询，不适合范围查询；







## Java的Lock底层原理

### 7.ReentrantLock怎么实现可重入

ReentrantLock获取锁的操作都是重写了AQS的tryAcquire方法

ReentrantLock实现基于AQS，可重入功能基于同步状态state，可重入过程：

某一线程获取锁后，将state值+1，并记录当前持有锁的线程，当再有线程来获取锁时，判断是否是持有锁的线程，如果是，则将state+1，不是则阻塞线程。线程释放锁时，state值-1，当state值为0时，表示当前线程已释放锁。可唤醒其他线程，重新竞争锁。



### 8. ReentrantLock怎么实现非公平锁

内部Sync类继承AQS，NofairSync和FairSync是Sync的子类，默认使用非公平锁。

非公平锁原理：一个线程获取到锁，其他没获取到锁的线程加入AQS的同步队列中等待，线程执行完，释放锁后，其他线程重新非公平竞争锁。

lock方法CAS操作将state从0改为1，修改成功才是获取锁成功，加锁成功会将AQS的独占线程变量设为该线程；加锁失败，调用AQS的acquire方法，转到NofairSync的tryAcquire方法再尝试获取锁，失败则addWaiter方法加入同步队列等待；

unlock方法，调AQS的release方法释放锁，转到Sync的tryRelease方法，将state-1，如果-1后等于0，释放锁成功。并唤醒同步队列的下一个结点，重新竞争锁。此时，所有线程都可竞争锁；



### 9.如何实现公平锁？

释放逻辑一样，都是unlock方法；

FairSync的lock方法，调AQS的acquire方法，转到FairSync的tryAcquire方法，与非公平锁的不同点：

（1）判断hasQueuedPredecessors，即当前AQS同步队列中是否还有等待线程，如果有，需要让当前线程到队尾排队；

### 10. AQS底层原理



### 















## MySQL问题准备

### 8.怎么解决死锁

**死锁发生的原因**

经典场景是加锁的顺序不一致，如：事务A给id=1记录加锁，然后update第二行；事务B已经持有第二行记录的锁，然后update第一行记录；这样循环等待就出现死锁了

**解决**

* 死锁真的发生时，需要查看死锁日志，分析出问题的SQL，以及场景。
* 针对经典死锁场景，可以先对数据排序，保证每个线程按固定顺序处理记录，降低死锁出现的可能；
* 给表添加合理的索引，如果update时没有用到索引，会为每一行记录加锁，死锁概率加大；
* 避免大事务；











## 分布式问题准备

分布式服务：
分布式服务建设的目标是为了解决一些传统的单体服务的不足：
1、单一硬件的性能瓶颈，一个配置再高的服务，也无法支撑起来海量数据和互联网领域的极高的TPS处理能力的。
2、超大系统的复杂度，把所有功能都集中在一个工程中，系统足够复杂了，相互之间的耦合性极难梳理清楚，如果是把服务拆分，单个服务承担相对单一的职责，是团队内部的同学聚焦到一个服务内，更容易理的清楚。
3、提高大团队的多项目并行能力：如果有100个项目在同一个工程中并行，几乎是不可能实现的。

分布式带来的问题：
1、服务治理的难度：如何理清楚服务之间的依赖关系，通过MQ对服务之间的依赖进行解耦，部分服务不可用的降级能力。
2、硬件/网络等带来的问题：多节点集群部署，减少单点故障的影响。
3、跨服务的问题追踪和排查难度加大：调用链追踪+问题报警能力的建设
4、集群雪崩效应：服务依赖梳理 + 熔断策略
5、分布式事务等的业界难题的解决办法



## RocketMQ问题准备

### 9. 怎么保证消息顺序

RocketMQ不保证全局消息顺序，只是分区顺序。如果要全局顺序，可以将队列数设为1.

为什么不能做到全局顺序？

因为消费者可以同时处理多个队列，多个队列是同时拉取并消费的，这样无法保证全局顺序了。但是可以保证同一个队列里的消息是FIFO的。

**（1）顺序发送原理**

局部有序+同步发送

顺序发送的原理：同一类消息发到相同的队列即可，为了保证先发的消息先存储到消息队列，需要使用同步发送方式，即发送消息后等待Broker返回结果，支持失败重试；

**（2）顺序消费原理**

集群消费

一条消息只会被一个消费者消费，原理是同一个消息队列只允许消费者中的一个消费线程拉取消费，顺序消费场景下消费线程请求到Broker先申请独占锁，获取锁成功才允许消费；

消费成功后，需要给Broker提交消费进度，更新消费位点信息，避免下次又拉取到已消费的消息。如果消费时抛出异常，则不会提交消费进度，进度一直阻塞在当前消息处，也不会继续消费后续消息，从而保证顺序消费；



### 10. 怎么保证消息不丢失？

**（1）生产阶段Producer**

同步发送+重试机制+多个master结点

Producer发送消息给Broker，Broker收到后，返回ACK给生产者，生产者只要收到ACK，就确认生产阶段消息未丢失；

发送消息失败或是超时，会重试

异步方式需要重写回调方法，在回调方法里检查发送结果

**（2）存储阶段**

同步刷盘策略+同步复制机制

Broker使用同步刷盘机制，消息存储磁盘成功，才会返回响应。

Broker集群部署，一主多从，默认是消息写入master成功就返回ACK给生产者，接着消息异步复制到slave节点；

（为了进一步提高可靠性，可采用同步复制的方式，即从结点也存储完成，才返回ACK）

**（3）消费阶段**

消费者从Broker拉取消息，执行业务逻辑，消费成功后返回consume success给Broker，如果Broker未收到响应状态，消费者下次还会拉取到该条消息，进行重试。有效避免了消费过程中发生异常，或是网络传输丢失；



### 11.保证消息不重复消费？

由消费方保证幂等性

比如：使用数据库的唯一索引保证







## 分库分表

### 12.分库分表怎么做？

#### **水平切分**

理解：单张表的数据量太大，需要水平切分，即把表数据按某种规则切分成多张表，分库分表顺序应该是先垂直，后水平；

**水平分表**：数据量巨大的单张表，按照Range或Hash取模等，切分到多张表里，但是因为在一个库里，库级别仍然存在IO瓶颈，不建议使用；

**水平分库分表**：单张表切分到多个服务器上，每个服务器有相应的库与表，只是表中数据集合不同。

* RANGE： 1-10000是一个表，10000-20000是一个表。。

* Hash取模：取用户id，然后hash取模，分配到不同数据库上；
* 按照地理位置维度分，如北美得克萨斯州，弗洛里达洲等。。
* 按时间维度，比如按月划分，一个月数据一张表



#### **垂直切分**

**理解**：单个库太大，且原因是因为表多而造成数据多，那么就用垂直切分，根据业务切分成不同的库；

**垂直分表**：大表拆小表，基于列字段进行，表中字段较多，将常用的，核心的数据拆为主表，

**垂直分库**：针对不同业务进行拆分，比如：User一个库，Order一个库，商品Producet一个库，（没拆分之前，全部落到单一库上，单库处理能力成为系统瓶颈）



### 13.分库分表后怎么保证全局ID唯一性？









## 异步加载和多级缓存

### 14.怎么解释？





















